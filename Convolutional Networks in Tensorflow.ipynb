{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks in Tensorflow\n",
    "\n",
    "This notebook will show you how to implement convolutional neural networks in Tensorflow using the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Organize the data files\n",
    "\n",
    "We will use the [Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) data set that contains pictures of objects belonging to 101 categories. The data set has already been downloaded to the `/data400/101_ObjectCategories/` shared directory.\n",
    "\n",
    "First, let's determine what the 101 categories are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [s.split(\"/\")[-1] for s in glob(\"/data400/101_ObjectCategories/*\")]\n",
    "print(len(categories))\n",
    "categories[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a list of all of the images in all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for cat_id, cat in enumerate(categories):\n",
    "    images.extend(\n",
    "        (cat_id, img) for img in\n",
    "         glob(\"/data400/101_ObjectCategories/%s/*.jpg\" % cat)\n",
    "    )\n",
    "    \n",
    "print(len(images))\n",
    "np.random.shuffle(images)\n",
    "images[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Set up the model in Tensorflow\n",
    "\n",
    "Now we set up the Tensorflow model. We use the Keras API. Since our model is just a sequence of layers, one after the other, we use `tf.keras.Sequential` to set up our model. This takes as input a list of layers. We have:\n",
    "\n",
    "- convolutional layer: [`Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), since these are images \n",
    "- max pooling layers: [`MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "- flatten: [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), which takes an N-D tensor and turns it into a 2-D tensor, with one dimension for each image and another for everything else.\n",
    "- dense layers: [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "\n",
    "We use ReLU as the activation function, except in the last layer where we use softmax. (Why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                  data_format='channels_last',\n",
    "                  activation='relu',\n",
    "                  input_shape=(60, 45, 3)),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Read in the data and train the model.\n",
    "\n",
    "Now we'll read in each image, decode it, and resize it to a 60 x 45 x 3 tensor. (Each image is 60 x 45, with 3 color channels.)\n",
    "\n",
    "We also need to keep track of the corresponding category id (`cat_id`) of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode images one by one and resize them to 60 x 45.\n",
    "# (We also keep track of the actual cat_id of each image.)\n",
    "imgs = []\n",
    "cat_ids = []\n",
    "for cat_id, img_file in images:\n",
    "    img_decoded = tf.image.decode_jpeg(\n",
    "        tf.read_file(img_file),\n",
    "        channels=3\n",
    "    )\n",
    "    img_resized = tf.image.resize_images(img_decoded, [60, 45])\n",
    "    imgs.append(img_resized)\n",
    "    cat_ids.append(cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each image inside `imgs` is a 60 x 45 x 3 tensor. We'll stack these images along a 4th dimension to produce a 4D tensor. Now we will have different images along the `axis=0` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each img_resized is a 3D tensor. Stack them along axis=0 to \n",
    "# produce a 4D tensor. (The new dimension is just the batch size.)\n",
    "x_train = tf.stack(imgs[:4000], axis=0)\n",
    "\n",
    "# cat_ids are integers from 0 to len(categories)\n",
    "y_train = utils.to_categorical(cat_ids[:4000], len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model.\n",
    "model.fit(x_train, y_train, verbose=1, epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We need to evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.stack(imgs[4000:], axis=0)\n",
    "\n",
    "# cat_ids are integers from 0 to len(categories)\n",
    "y_test = utils.to_categorical(cat_ids[4000:], len(categories))\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
